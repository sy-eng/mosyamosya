{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3876d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ,  0 , loss:  2.3658\n",
      "0 ,  500 , loss:  2.0936\n",
      "0 ,  1000 , loss:  1.7340\n",
      "0 ,  1500 , loss:  1.1211\n",
      "0 ,  2000 , loss:  0.9431\n",
      "0 ,  2500 , loss:  0.8506\n",
      "1 ,  0 , loss:  0.7993\n",
      "1 ,  500 , loss:  0.7630\n",
      "1 ,  1000 , loss:  0.5759\n",
      "1 ,  1500 , loss:  0.5655\n",
      "1 ,  2000 , loss:  0.3086\n",
      "1 ,  2500 , loss:  0.2391\n",
      "2 ,  0 , loss:  0.4619\n",
      "2 ,  500 , loss:  0.1765\n",
      "2 ,  1000 , loss:  0.3125\n",
      "2 ,  1500 , loss:  0.2721\n",
      "2 ,  2000 , loss:  0.2927\n",
      "2 ,  2500 , loss:  0.4070\n",
      "3 ,  0 , loss:  0.5485\n",
      "3 ,  500 , loss:  0.3190\n",
      "3 ,  1000 , loss:  0.4562\n",
      "3 ,  1500 , loss:  0.5576\n",
      "3 ,  2000 , loss:  0.1601\n",
      "3 ,  2500 , loss:  0.3819\n",
      "4 ,  0 , loss:  0.8083\n",
      "4 ,  500 , loss:  0.4889\n",
      "4 ,  1000 , loss:  0.3376\n",
      "4 ,  1500 , loss:  0.4201\n",
      "4 ,  2000 , loss:  0.3305\n",
      "4 ,  2500 , loss:  0.2217\n",
      "5 ,  0 , loss:  0.2545\n",
      "5 ,  500 , loss:  0.2013\n",
      "5 ,  1000 , loss:  0.1354\n",
      "5 ,  1500 , loss:  0.2905\n",
      "5 ,  2000 , loss:  0.1671\n",
      "5 ,  2500 , loss:  0.2128\n",
      "6 ,  0 , loss:  0.3229\n",
      "6 ,  500 , loss:  0.3608\n",
      "6 ,  1000 , loss:  0.2401\n",
      "6 ,  1500 , loss:  0.2425\n",
      "6 ,  2000 , loss:  0.3224\n",
      "6 ,  2500 , loss:  0.2006\n",
      "7 ,  0 , loss:  0.4082\n",
      "7 ,  500 , loss:  0.2797\n",
      "7 ,  1000 , loss:  0.2455\n",
      "7 ,  1500 , loss:  0.4870\n",
      "7 ,  2000 , loss:  0.1967\n",
      "7 ,  2500 , loss:  0.3187\n",
      "8 ,  0 , loss:  0.2131\n",
      "8 ,  500 , loss:  0.8242\n",
      "8 ,  1000 , loss:  0.1689\n",
      "8 ,  1500 , loss:  0.1327\n",
      "8 ,  2000 , loss:  0.2633\n",
      "8 ,  2500 , loss:  0.3546\n",
      "9 ,  0 , loss:  0.2522\n",
      "9 ,  500 , loss:  0.1928\n",
      "9 ,  1000 , loss:  0.1183\n",
      "9 ,  1500 , loss:  0.1671\n",
      "9 ,  2000 , loss:  0.2286\n",
      "9 ,  2500 , loss:  0.4193\n",
      "10 ,  0 , loss:  0.5291\n",
      "10 ,  500 , loss:  0.1397\n",
      "10 ,  1000 , loss:  0.0496\n",
      "10 ,  1500 , loss:  0.3852\n",
      "10 ,  2000 , loss:  0.5386\n",
      "10 ,  2500 , loss:  0.2916\n",
      "11 ,  0 , loss:  0.3339\n",
      "11 ,  500 , loss:  0.1576\n",
      "11 ,  1000 , loss:  0.2070\n",
      "11 ,  1500 , loss:  0.1531\n",
      "11 ,  2000 , loss:  0.6098\n",
      "11 ,  2500 , loss:  0.5060\n",
      "12 ,  0 , loss:  0.0642\n",
      "12 ,  500 , loss:  0.1561\n",
      "12 ,  1000 , loss:  0.4211\n",
      "12 ,  1500 , loss:  0.1008\n",
      "12 ,  2000 , loss:  0.2881\n",
      "12 ,  2500 , loss:  0.0903\n",
      "13 ,  0 , loss:  0.4317\n",
      "13 ,  500 , loss:  0.5510\n",
      "13 ,  1000 , loss:  0.3337\n",
      "13 ,  1500 , loss:  0.1475\n",
      "13 ,  2000 , loss:  0.0339\n",
      "13 ,  2500 , loss:  0.2595\n",
      "14 ,  0 , loss:  0.1984\n",
      "14 ,  500 , loss:  0.3536\n",
      "14 ,  1000 , loss:  0.3316\n",
      "14 ,  1500 , loss:  0.5186\n",
      "14 ,  2000 , loss:  0.0554\n",
      "14 ,  2500 , loss:  0.2448\n",
      "15 ,  0 , loss:  0.3148\n",
      "15 ,  500 , loss:  0.5707\n",
      "15 ,  1000 , loss:  0.3297\n",
      "15 ,  1500 , loss:  0.2240\n",
      "15 ,  2000 , loss:  0.2261\n",
      "15 ,  2500 , loss:  0.7472\n",
      "16 ,  0 , loss:  0.4448\n",
      "16 ,  500 , loss:  0.1149\n",
      "16 ,  1000 , loss:  0.1096\n",
      "16 ,  1500 , loss:  0.1468\n",
      "16 ,  2000 , loss:  0.3192\n",
      "16 ,  2500 , loss:  0.0978\n",
      "17 ,  0 , loss:  0.1523\n",
      "17 ,  500 , loss:  0.0718\n",
      "17 ,  1000 , loss:  0.2510\n",
      "17 ,  1500 , loss:  0.1881\n",
      "17 ,  2000 , loss:  0.4589\n",
      "17 ,  2500 , loss:  0.2322\n",
      "18 ,  0 , loss:  0.1069\n",
      "18 ,  500 , loss:  0.5339\n",
      "18 ,  1000 , loss:  0.2541\n",
      "18 ,  1500 , loss:  0.1739\n",
      "18 ,  2000 , loss:  0.3101\n",
      "18 ,  2500 , loss:  0.1002\n",
      "19 ,  0 , loss:  0.5478\n",
      "19 ,  500 , loss:  0.6903\n",
      "19 ,  1000 , loss:  0.5316\n",
      "19 ,  1500 , loss:  0.6084\n",
      "19 ,  2000 , loss:  0.1678\n",
      "19 ,  2500 , loss:  0.0656\n",
      "20 ,  0 , loss:  0.5692\n",
      "20 ,  500 , loss:  0.7765\n",
      "20 ,  1000 , loss:  0.1072\n",
      "20 ,  1500 , loss:  0.1508\n",
      "20 ,  2000 , loss:  0.1418\n",
      "20 ,  2500 , loss:  0.5133\n",
      "21 ,  0 , loss:  1.0084\n",
      "21 ,  500 , loss:  0.1315\n",
      "21 ,  1000 , loss:  0.7466\n",
      "21 ,  1500 , loss:  0.1464\n",
      "21 ,  2000 , loss:  0.2011\n",
      "21 ,  2500 , loss:  0.2309\n",
      "22 ,  0 , loss:  0.0684\n",
      "22 ,  500 , loss:  0.2201\n",
      "22 ,  1000 , loss:  0.6647\n",
      "22 ,  1500 , loss:  0.1267\n",
      "22 ,  2000 , loss:  0.8032\n",
      "22 ,  2500 , loss:  0.2693\n",
      "23 ,  0 , loss:  0.2077\n",
      "23 ,  500 , loss:  0.4725\n",
      "23 ,  1000 , loss:  0.3348\n",
      "23 ,  1500 , loss:  0.1880\n",
      "23 ,  2000 , loss:  0.5140\n",
      "23 ,  2500 , loss:  0.1121\n",
      "24 ,  0 , loss:  0.3564\n",
      "24 ,  500 , loss:  0.7328\n",
      "24 ,  1000 , loss:  0.2390\n",
      "24 ,  1500 , loss:  0.3108\n",
      "24 ,  2000 , loss:  0.0537\n",
      "24 ,  2500 , loss:  0.1929\n",
      "25 ,  0 , loss:  0.1732\n",
      "25 ,  500 , loss:  0.2127\n",
      "25 ,  1000 , loss:  0.4044\n",
      "25 ,  1500 , loss:  0.3789\n",
      "25 ,  2000 , loss:  0.1012\n",
      "25 ,  2500 , loss:  0.2899\n",
      "26 ,  0 , loss:  0.5988\n",
      "26 ,  500 , loss:  0.1857\n",
      "26 ,  1000 , loss:  0.2157\n",
      "26 ,  1500 , loss:  0.2435\n",
      "26 ,  2000 , loss:  0.2747\n",
      "26 ,  2500 , loss:  0.1242\n",
      "27 ,  0 , loss:  0.0959\n",
      "27 ,  500 , loss:  0.2584\n",
      "27 ,  1000 , loss:  0.2634\n",
      "27 ,  1500 , loss:  0.1258\n",
      "27 ,  2000 , loss:  0.6133\n",
      "27 ,  2500 , loss:  0.5212\n",
      "28 ,  0 , loss:  0.1202\n",
      "28 ,  500 , loss:  0.3872\n",
      "28 ,  1000 , loss:  0.5017\n",
      "28 ,  1500 , loss:  0.4641\n",
      "28 ,  2000 , loss:  0.6054\n",
      "28 ,  2500 , loss:  0.0876\n",
      "29 ,  0 , loss:  0.3310\n",
      "29 ,  500 , loss:  0.1072\n",
      "29 ,  1000 , loss:  0.6494\n",
      "29 ,  1500 , loss:  0.3974\n",
      "29 ,  2000 , loss:  0.1407\n",
      "29 ,  2500 , loss:  0.4273\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch画像用\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batchSize = 20\n",
    "epochNum = 30\n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 1000\n",
    "output_dim = 10\n",
    "\n",
    "learningRate = 0.01\n",
    "\n",
    "# データセットの取得\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "# DataLoaderの作成\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "    \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.inputLayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.outputLayer = nn.Linear(hidden_dim, output_dim)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        h = torch.sigmoid(self.inputLayer(x))\n",
    "        o = F.log_softmax(self.outputLayer(h), dim=1)\n",
    "        return o\n",
    "\n",
    "def oneHot(label):\n",
    "    return torch.eye(output_dim)[label]\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Encoder(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(epochNum):\n",
    "    for j, (image, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image.view(-1, input_dim))\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            print(i, \", \", j, \",\", f'loss: {loss: 0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f490dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation\n",
      "0.9263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluation\")\n",
    "\n",
    "dataNum = 0\n",
    "correctNum = 0\n",
    "\n",
    "for image, label in test_loader:\n",
    "#for image, label in train_loader:\n",
    "    dataNum = dataNum + 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(image.view(-1, input_dim))\n",
    "\n",
    "    out_numpy = out.cpu().detach().numpy()[0]\n",
    "    \n",
    "    if np.argmax(out_numpy) == label.cpu().detach().numpy()[0]:\n",
    "        correctNum = correctNum + 1\n",
    "        \n",
    "print(correctNum/dataNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7958f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ,  0 , loss:  0.2554\n",
      "0 ,  500 , loss:  0.0900\n",
      "0 ,  1000 , loss:  0.0899\n",
      "0 ,  1500 , loss:  0.0894\n",
      "0 ,  2000 , loss:  0.0896\n",
      "0 ,  2500 , loss:  0.0898\n",
      "1 ,  0 , loss:  0.0897\n",
      "1 ,  500 , loss:  0.0892\n",
      "1 ,  1000 , loss:  0.0903\n",
      "1 ,  1500 , loss:  0.0895\n",
      "1 ,  2000 , loss:  0.0894\n",
      "1 ,  2500 , loss:  0.0893\n",
      "2 ,  0 , loss:  0.0883\n",
      "2 ,  500 , loss:  0.0886\n",
      "2 ,  1000 , loss:  0.0889\n",
      "2 ,  1500 , loss:  0.0888\n",
      "2 ,  2000 , loss:  0.0883\n",
      "2 ,  2500 , loss:  0.0875\n",
      "3 ,  0 , loss:  0.0891\n",
      "3 ,  500 , loss:  0.0880\n",
      "3 ,  1000 , loss:  0.0881\n",
      "3 ,  1500 , loss:  0.0872\n",
      "3 ,  2000 , loss:  0.0868\n",
      "3 ,  2500 , loss:  0.0881\n",
      "4 ,  0 , loss:  0.0882\n",
      "4 ,  500 , loss:  0.0868\n",
      "4 ,  1000 , loss:  0.0863\n",
      "4 ,  1500 , loss:  0.0871\n",
      "4 ,  2000 , loss:  0.0865\n",
      "4 ,  2500 , loss:  0.0859\n",
      "5 ,  0 , loss:  0.0862\n",
      "5 ,  500 , loss:  0.0847\n",
      "5 ,  1000 , loss:  0.0850\n",
      "5 ,  1500 , loss:  0.0852\n",
      "5 ,  2000 , loss:  0.0849\n",
      "5 ,  2500 , loss:  0.0836\n",
      "6 ,  0 , loss:  0.0849\n",
      "6 ,  500 , loss:  0.0846\n",
      "6 ,  1000 , loss:  0.0853\n",
      "6 ,  1500 , loss:  0.0870\n",
      "6 ,  2000 , loss:  0.0880\n",
      "6 ,  2500 , loss:  0.0816\n",
      "7 ,  0 , loss:  0.0836\n",
      "7 ,  500 , loss:  0.0810\n",
      "7 ,  1000 , loss:  0.0821\n",
      "7 ,  1500 , loss:  0.0821\n",
      "7 ,  2000 , loss:  0.0835\n",
      "7 ,  2500 , loss:  0.0838\n",
      "8 ,  0 , loss:  0.0810\n",
      "8 ,  500 , loss:  0.0814\n",
      "8 ,  1000 , loss:  0.0829\n",
      "8 ,  1500 , loss:  0.0821\n",
      "8 ,  2000 , loss:  0.0837\n",
      "8 ,  2500 , loss:  0.0843\n",
      "9 ,  0 , loss:  0.0780\n",
      "9 ,  500 , loss:  0.0813\n",
      "9 ,  1000 , loss:  0.0829\n",
      "9 ,  1500 , loss:  0.0762\n",
      "9 ,  2000 , loss:  0.0779\n",
      "9 ,  2500 , loss:  0.0776\n",
      "10 ,  0 , loss:  0.0781\n",
      "10 ,  500 , loss:  0.0740\n",
      "10 ,  1000 , loss:  0.0830\n",
      "10 ,  1500 , loss:  0.0800\n",
      "10 ,  2000 , loss:  0.0782\n",
      "10 ,  2500 , loss:  0.0726\n",
      "11 ,  0 , loss:  0.0799\n",
      "11 ,  500 , loss:  0.0766\n",
      "11 ,  1000 , loss:  0.0669\n",
      "11 ,  1500 , loss:  0.0773\n",
      "11 ,  2000 , loss:  0.0655\n",
      "11 ,  2500 , loss:  0.0676\n",
      "12 ,  0 , loss:  0.0730\n",
      "12 ,  500 , loss:  0.0839\n",
      "12 ,  1000 , loss:  0.0749\n",
      "12 ,  1500 , loss:  0.0748\n",
      "12 ,  2000 , loss:  0.0728\n",
      "12 ,  2500 , loss:  0.0722\n",
      "13 ,  0 , loss:  0.0703\n",
      "13 ,  500 , loss:  0.0692\n",
      "13 ,  1000 , loss:  0.0674\n",
      "13 ,  1500 , loss:  0.0746\n",
      "13 ,  2000 , loss:  0.0701\n",
      "13 ,  2500 , loss:  0.0646\n",
      "14 ,  0 , loss:  0.0693\n",
      "14 ,  500 , loss:  0.0685\n",
      "14 ,  1000 , loss:  0.0655\n",
      "14 ,  1500 , loss:  0.0569\n",
      "14 ,  2000 , loss:  0.0645\n",
      "14 ,  2500 , loss:  0.0683\n",
      "15 ,  0 , loss:  0.0748\n",
      "15 ,  500 , loss:  0.0616\n",
      "15 ,  1000 , loss:  0.0621\n",
      "15 ,  1500 , loss:  0.0692\n",
      "15 ,  2000 , loss:  0.0629\n",
      "15 ,  2500 , loss:  0.0502\n",
      "16 ,  0 , loss:  0.0653\n",
      "16 ,  500 , loss:  0.0492\n",
      "16 ,  1000 , loss:  0.0691\n",
      "16 ,  1500 , loss:  0.0617\n",
      "16 ,  2000 , loss:  0.0583\n",
      "16 ,  2500 , loss:  0.0569\n",
      "17 ,  0 , loss:  0.0582\n",
      "17 ,  500 , loss:  0.0600\n",
      "17 ,  1000 , loss:  0.0569\n",
      "17 ,  1500 , loss:  0.0582\n",
      "17 ,  2000 , loss:  0.0657\n",
      "17 ,  2500 , loss:  0.0587\n",
      "18 ,  0 , loss:  0.0595\n",
      "18 ,  500 , loss:  0.0595\n",
      "18 ,  1000 , loss:  0.0542\n",
      "18 ,  1500 , loss:  0.0663\n",
      "18 ,  2000 , loss:  0.0661\n",
      "18 ,  2500 , loss:  0.0576\n",
      "19 ,  0 , loss:  0.0567\n",
      "19 ,  500 , loss:  0.0527\n",
      "19 ,  1000 , loss:  0.0541\n",
      "19 ,  1500 , loss:  0.0500\n",
      "19 ,  2000 , loss:  0.0558\n",
      "19 ,  2500 , loss:  0.0588\n",
      "20 ,  0 , loss:  0.0532\n",
      "20 ,  500 , loss:  0.0614\n",
      "20 ,  1000 , loss:  0.0638\n",
      "20 ,  1500 , loss:  0.0552\n",
      "20 ,  2000 , loss:  0.0517\n",
      "20 ,  2500 , loss:  0.0542\n",
      "21 ,  0 , loss:  0.0564\n",
      "21 ,  500 , loss:  0.0428\n",
      "21 ,  1000 , loss:  0.0548\n",
      "21 ,  1500 , loss:  0.0526\n",
      "21 ,  2000 , loss:  0.0444\n",
      "21 ,  2500 , loss:  0.0460\n",
      "22 ,  0 , loss:  0.0481\n",
      "22 ,  500 , loss:  0.0523\n",
      "22 ,  1000 , loss:  0.0472\n",
      "22 ,  1500 , loss:  0.0476\n",
      "22 ,  2000 , loss:  0.0492\n",
      "22 ,  2500 , loss:  0.0391\n",
      "23 ,  0 , loss:  0.0489\n",
      "23 ,  500 , loss:  0.0524\n",
      "23 ,  1000 , loss:  0.0547\n",
      "23 ,  1500 , loss:  0.0527\n",
      "23 ,  2000 , loss:  0.0434\n",
      "23 ,  2500 , loss:  0.0509\n",
      "24 ,  0 , loss:  0.0496\n",
      "24 ,  500 , loss:  0.0534\n",
      "24 ,  1000 , loss:  0.0505\n",
      "24 ,  1500 , loss:  0.0437\n",
      "24 ,  2000 , loss:  0.0439\n",
      "24 ,  2500 , loss:  0.0397\n",
      "25 ,  0 , loss:  0.0475\n",
      "25 ,  500 , loss:  0.0465\n",
      "25 ,  1000 , loss:  0.0435\n",
      "25 ,  1500 , loss:  0.0412\n",
      "25 ,  2000 , loss:  0.0403\n",
      "25 ,  2500 , loss:  0.0466\n",
      "26 ,  0 , loss:  0.0501\n",
      "26 ,  500 , loss:  0.0419\n",
      "26 ,  1000 , loss:  0.0453\n",
      "26 ,  1500 , loss:  0.0400\n",
      "26 ,  2000 , loss:  0.0469\n",
      "26 ,  2500 , loss:  0.0423\n",
      "27 ,  0 , loss:  0.0456\n",
      "27 ,  500 , loss:  0.0351\n",
      "27 ,  1000 , loss:  0.0430\n",
      "27 ,  1500 , loss:  0.0512\n",
      "27 ,  2000 , loss:  0.0474\n",
      "27 ,  2500 , loss:  0.0432\n",
      "28 ,  0 , loss:  0.0381\n",
      "28 ,  500 , loss:  0.0348\n",
      "28 ,  1000 , loss:  0.0357\n",
      "28 ,  1500 , loss:  0.0406\n",
      "28 ,  2000 , loss:  0.0453\n",
      "28 ,  2500 , loss:  0.0441\n",
      "29 ,  0 , loss:  0.0363\n",
      "29 ,  500 , loss:  0.0418\n",
      "29 ,  1000 , loss:  0.0520\n",
      "29 ,  1500 , loss:  0.0446\n",
      "29 ,  2000 , loss:  0.0300\n",
      "29 ,  2500 , loss:  0.0388\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch画像用\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batchSize = 20\n",
    "epochNum = 30\n",
    "\n",
    "input_dim = 28 * 28\n",
    "hidden_dim = 1000\n",
    "output_dim = 10\n",
    "\n",
    "learningRate = 0.01\n",
    "\n",
    "# データセットの取得\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "# DataLoaderの作成\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "\n",
    "    batch_size=batchSize,\n",
    "    shuffle=True,\n",
    "    \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.inputLayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.outputLayer = nn.Linear(hidden_dim, output_dim)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        h = torch.sigmoid(self.inputLayer(x))\n",
    "        o = torch.sigmoid(self.outputLayer(h))\n",
    "        return o\n",
    "\n",
    "def oneHot(label):\n",
    "    return torch.eye(output_dim)[label]\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Encoder(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(epochNum):\n",
    "    for j, (image, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image.view(-1, input_dim))\n",
    "\n",
    "        loss = criterion(output, oneHot(label))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            print(i, \", \", j, \",\", f'loss: {loss: 0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf704a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation\n",
      "0.8009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluation\")\n",
    "\n",
    "dataNum = 0\n",
    "correctNum = 0\n",
    "\n",
    "for image, label in test_loader:\n",
    "#for image, label in train_loader:\n",
    "    dataNum = dataNum + 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(image.view(-1, input_dim))\n",
    "\n",
    "    out_numpy = out.cpu().detach().numpy()[0]\n",
    "    \n",
    "    if np.argmax(out_numpy) == label.cpu().detach().numpy()[0]:\n",
    "        correctNum = correctNum + 1\n",
    "        \n",
    "print(correctNum/dataNum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
